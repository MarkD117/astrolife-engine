# "A Day in the life" - HackAthlone
On day one of our SpaceApps journey we attempted to build a Space Biology Knowledge Engine, hosted on a webpage, utilisng AI that we had trained on Data provided by NASA. Unfortunately, our collective knowledge gaps proved too much to acheive a viable prototype and we have had to pivot into a new challenge.

This has given us a valuable learning experience both in adapting our approach from concept to build and given us an insight into where we can direct future learning. It is however, not a total failure, as we have gained an experience and also, througout our attempt we documented everything, with text, imagery and video, we met many amazing fellow hackers, we collaborated and learned.

Which leads us to our new challenge, "A day in the life" - HackAthlone will be a documentary of sorts, hosted on a webpage of our making, will feature our process for our first attempt, testimonials, video interviews both with the team and fellow hackers and imagery.

## astrolife-engine
A web application that leverages AI, knowledge graphs, and/or other tools to summarize the 608 NASA bioscience publications listed in an online repository, and enables users to explore the impacts and results from the experiments those publications describe.

## Index - Table of contents
* [Tasks](#tasks)
* Placeholder
* placeholder

## Tasks
### Google Cloud Platform Team: Dylan/Ciara
Enabled APIs
Vertex AI API - To train machine learning modules.
Cloud Storage API - Storing the NASA Repository (.CSV files).

Created Bucket
Downloaded the 608 publication links from the NASA resource repository in .CSV format and added them to the bucket on GCP.

Trained AI Model
Imported the .CSV files from the bucket to Vertex AI and trained the AI model.

### GoDaddy Domain/Website Build Team: Mark
Chose a .study domain as other options didnâ€™t allow for WHOIS security.

### Graph Integration Team: Alex/George
Researching methods for integrating graphs/ taking graph data from repositories.




